<!doctype html><html lang=en-us><head><meta charset=utf-8><title>Infrastructure as code in the home - one year on - skouf.com</title><meta name=generator content="Hugo 0.118.2"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Nik Skoufis"><meta name=description content="One year on, I revisit my home infrastructure as code setup. I explore what worked, what didn&rsquo;t and what has changed over the last year."><meta name=keywords content><meta property="og:site_name" content="skouf.com"><meta property="og:title" content="Infrastructure as code in the home - one year on"><meta property="og:url" content="https://www.skouf.com/posts/iac-in-the-home-one-year-on/"><meta property="og:image" content="https://www.skouf.com/servers.jpg"><meta property="og:description" content="One year on, I revisit my home infrastructure as code setup. I explore what worked, what didn&rsquo;t and what has changed over the last year."><meta property="og:type" content="blog"><link rel="shortcut icon" href=/image/theme/favicon.ico><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,400;0,700;1,400&display=swap" rel=stylesheet><link rel=stylesheet href=/css/style.min.d6304ed7a67ce303c1f52e11a8da46aba4daaea2bac2caaad0361d1fc0454013.css><link rel=stylesheet href=/css/syntax.min.786ee623d2964a9ec341cc6421d7b4bbdebeaf2215b5f5729d057ec27374de5f.css><link rel=alternate href=https://www.skouf.com/index.xml type=application/rss+xml title=skouf.com></head><body class="text-dark-blue-grey bg-light-blue-grey"><div class=overflow-hidden><header class="py-2 md:py-8 text-center bg-hero-green"><h1><a class="text-2xl md:text-4xl font-bold text-dark-green" href=https://www.skouf.com/>skouf.com</a></h1><p class="tagline text-sm md:text-base md:py-4 text-dark-green">The website of Nik Skoufis</p></header><main class="my-0 mx-auto max-w-prose p-4"><article class=pb-12 itemscope itemtype=http://schema.org/BlogPosting><div class="py-2 md:py-6 mx-auto max-w-screen-sm"><h1 class="text-3xl font-bold">Infrastructure as code in the home - one year on</h1><p class="text-dark-blue-grey/90 my-2 text-right"><time itemprop=datePublished datetime=2019-01-09T00:43:25Z>2019.01.09</time></p></div><div class="prose prose-slate prose-code:before:hidden prose-code:after:hidden"><p><em>It&rsquo;s been almost a year since I published my original article on running my Kubernetes setup at home.
Have a read of <a href=https://www.skouf.com/posts/iac-in-the-home/>the original</a> for context.</em></p><figure><a href=#servers.jpg><img sizes="(min-width: 35em) 1200px, 100vw" srcset='/posts/iac-in-the-home-one-year-on/servers_hub7a1f3d404ab6696b140ae38456c2986_1575286_500x0_resize_q75_box.jpg 500w
, /posts/iac-in-the-home-one-year-on/servers_hub7a1f3d404ab6696b140ae38456c2986_1575286_800x0_resize_q75_box.jpg 800w
, /posts/iac-in-the-home-one-year-on/servers_hub7a1f3d404ab6696b140ae38456c2986_1575286_1200x0_resize_q75_box.jpg 1200w
, /posts/iac-in-the-home-one-year-on/servers_hub7a1f3d404ab6696b140ae38456c2986_1575286_1500x0_resize_q75_box.jpg 1500w' src=/posts/iac-in-the-home-one-year-on/servers.jpg alt="An image of a server rack, with the mesh doors closed. Many colored ethernet cables connect different components."></a>
<a class="hidden fixed top-0 bottom-0 left-0 right-0 z-[999] target:block bg-[rgb(0,0,0)]/80" href=#_ id=servers.jpg><img class="block w-full h-full object-contain m-0" src=/posts/iac-in-the-home-one-year-on/servers.jpg></a><figcaption><p>This is not what my home server looks like. Photo by <a href=https://unsplash.com/@tvick>Taylor Vick</a> on <a href=https://unsplash.com>Unsplash</a>.</p></figcaption></figure><p>I&rsquo;ve now been running Kubernetes at home for almost a year.
Some things have worked well, others have not, and I&rsquo;ve just finished a round of cleanup, maintenance, and re-acquainting myself with the system.
I thought it might be time for some reflection.</p><h2 id=recapping-goals-from-last-time>Recapping goals from last time</h2><p>Looking back on my last post on this topic, I had a few explicit goals.</p><ul><li>Disposability.
In other words, being able to tear down the system and start again quite easily if something breaks.</li><li>Change management.
Not letting small changes accumulate to the point where it&rsquo;s hard to understand the machine&rsquo;s state.</li><li>Flexibility.
The ability to re-provision the server with a new OS if desired.</li></ul><p>I&rsquo;ve managed to achieve some of these, but not others.</p><p>On the first goal of disposability, I failed to account for the fact that the system I had designed was, in fact, incredibly complicated.
With Matchbox, Terraform, Ignition configs and probably more gotchas, when it came to making changes, there was a lot to re-acquaint myself with.
So on that front, the setup I chose probably wasn&rsquo;t the best choice.
Automated headless provisioning is certainly very cool, and I learned a lot about PXE/iPXE/TFTP/DNS/DCHP in the process.
However it was really hard to remember how everything worked 10 months later.
I probably would have been far better served by something quite a lot simpler - perhaps just a USB stick that will bootstrap to Kubernetes.</p><p>On the second goal of change management, I feel it&rsquo;s gone reasonably well.
Using Kubernetes to run applications means no manual fiddling with the filesystem.
The only times I&rsquo;ve had to SSH in are to add new devices (see below), and to troubleshoot issues I&rsquo;ve had.
However aside from adding a new hard drive, it&rsquo;s mostly been to observe the state of the machine and not to fiddle.
So I&rsquo;m giving myself a tick on that one.</p><p>On the last goal of flexibility, it probably wasn&rsquo;t a great goal to begin with.
I certainly could just wipe everything and start again on a new OS if I wanted to, but it&rsquo;s a bit of a moot point.
I&rsquo;m happy enough with Kubernetes and the current performance of the server that I won&rsquo;t be moving any time soon.
Couple this with the entire exercise being more about learning that practicality, we&rsquo;ll call this one a wash and move on.</p><h2 id=things-that-have-proved-difficult>Things that have proved difficult</h2><p>Some things have proved incredibly difficult to get right.
Partly due to my own inexperience, but also due to bugs and weird quirks.
Here are a few of the issues I&rsquo;ve run in to.</p><h3 id=ingress>Ingress</h3><p>Ingress was confusing to set up when using a single node, and running on bare metal.</p><p>Ingress allows the outside world to talk to applications in your cluster
It&rsquo;s usually handled via a load balancer from a cloud provider (eg. and AWS ELB).
However, if you have a bare metal cluster, you need to use a reverse proxy like Nginx.
This is easy enough to configure via a Helm chart, but it requires some custom configuration.
Because I have the additional constraint of only a single node, Nginx has to bind to non-standard ports so as not to conflict with the bound ports used for the K8s API.
Not particularly bad, but I spent an afternoon baffled as to why my service and pod appeared to be working, and yet I couldn&rsquo;t access the service running in the pod.
Eventually I realised I was hitting the wrong port the whole time.</p><h3 id=storage>Storage</h3><p>Configuring storage has sucked.
A lot.
The ideal state is to have dynamic provisioning of persistent volumes, but this is pretty hard to do unless you&rsquo;re using cloud provider backed storage or a cluster filesystem.</p><p>First I tried <a href="https://medium.com/r/?url=https%3A%2F%2Fgithub.com%2Frook%2Frook">Rook</a>, a storage provider that works on top of the <a href="https://medium.com/r/?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FCeph_%28software%29">Ceph storage cluster software</a>.
After a very confusing time getting it set up, it seem to work ok.
Then I tried adding a new drive to the system, expecting things to Just Work.
This apparently wasn&rsquo;t supported in the version of Rook I was using (admittedly, my own fault for using something still in beta).
So I had to rip everything down and start again.</p><p>Then I had Rook working, but when I came time to mount an RWX PVC from multiple pods, I ran into the issue that apparently this <a href="https://medium.com/r/?url=https%3A%2F%2Fgithub.com%2Frook%2Frook%2Fissues%2F2300">just doesn&rsquo;t work right now</a>.
So then I had to tear Rook down and start again.</p><p>This time I used the <a href="https://medium.com/r/?url=https%3A%2F%2Fgithub.com%2Fkubernetes-incubator%2Fexternal-storage%2Ftree%2Fmaster%2Fnfs">NFS external storage provider</a>.
But this refused to work in a configuration with multiple nfs providers (one per drive) attached to the same provisioner and storage class.
Old documentation suggested this would work by creating a race to fulfill the storage, however in practice it seems that one provisioner would acquire a lock, and the other one would just do nothing.
Eventually I settled on a single NFS provisioner (because this allows for dynamic provisioning of PVs) with a btrfs filesystem that spanned multiple drives (<a href="https://medium.com/r/?url=https%3A%2F%2Fbtrfs.wiki.kernel.org%2Findex.php%2FUsing_Btrfs_with_Multiple_Devices">instructions on setting this up</a>).
Adding a new systemd mount unit and another one shot to perform a btrfs scan, and I finally have multiple pods mounting a single RWX claim with dynamic provisioning.</p><p>An aside here: LVM would be great here, but sadly this doesn&rsquo;t seem to be supported by CoreOS at the moment, nor as part of Ignition.
This might be a solution in the future.
That said, support for dynamic provisioning of local storage is still Coming Soon, so you&rsquo;d still need an NFS mount to facilitate this.</p><h3 id=upgrades>Upgrades</h3><p>As I mentioned above, disposability was a goal, but it hasn&rsquo;t gone as intended.
Firstly, the system of Matchbox, DnsMasq and Terraform is too complicated for me to remember 10 months on.
So re-provisioning from scratch is probably out of the question right now.
There&rsquo;s also the issue that I would lose all of my data, since it&rsquo;s only a cluster of one machine.</p><p>Thankfully, it appears that CoreOS upgrades are seamless.
I figured my OS was probably pretty old, but a simple reboot and I could see that the version number had updated to a more recent release, and the cluster came up with no ill effects.</p><p>Sadly, when I attempted to install Tectonic (after refreshing my memory on the whole Matchbox/Terraform/DnsMasq stuff), I found that Tectonic will not allow you to enter the same MAC address for the master and worker nodes.
This is annoying, because it seems as if Tectonic would have allowed me to do in-place Kubernetes version upgrades, instead of having to nuke things and start again.</p><p>For the moment I&rsquo;ve parked this.
I&rsquo;m happy that I&rsquo;ve got an up-to-date OS, and updating to the latest Kubernetes to get all the goodies that come with it will have to wait.
I&rsquo;m optimistic though, and the documentation has certainly become more comprehensive and easy to read since I last touched it.</p><h2 id=conclusion>Conclusion</h2><p>It&rsquo;s been a fun year or so running this cluster, and I&rsquo;m looking to keep the setup I&rsquo;ve got.
There have been a few issues along the way, but they&rsquo;ve all been great learning experiences.
Hopefully I&rsquo;ll have another update in a year or so.</p><hr></div></article><nav class="flex flex-col max-w-screen-sm mx-auto"><div class="flex justify-between flex-wrap pb-4"><a class="w-full text-left md:w-1/2 text-lg text-light-ocean-blue visited:text-dark-ocean-blue py-2" href=https://www.skouf.com/posts/istio-tls-policies/><span>Next:</span>
<span class=underline>Istio TLS policies - ugly bits and undocumented bits</span></a>
<a class="w-full text-right md:w-1/2 text-lg text-light-ocean-blue visited:text-dark-ocean-blue py-2" href=https://www.skouf.com/posts/iac-in-the-home/><span>Previous:</span>
<span class=underline>Infrastructure as code in the home</span></a></div><div class="flex justify-center pt-2"><a class="py-2 px-4 bg-hero-green text-lg font-bold text-dark-green" href=/>Home</a></div></nav></main><footer class="bg-hero-green text-dark-green py-4 md:py-8 mt-8 md:mt-16 text-center"><section class="max-w-screen-sm mx-auto px-4"><h2 class="font-bold text-2xl m-4">Author</h2><img class="mx-auto rounded-full h-24 w-24" src=/image/theme/author.jpg alt="A picture of the author"><div class="mx-auto my-4"><h3 class="font-bold text-xl text-center pb-2">Nik Skoufis</h3><p class="tagline text-center">Software developer, food lover</p></div><div class="flex justify-center space-x-2 my-4"><a href=https://github.com/niksko target=_blank aria-label="Link to my GitHub profile"><img class="h-8 w-8" src=/image/theme/github-logo.svg alt="The GitHub logo"></a>
<a href=https://hachyderm.io/@niksko target=_blank aria-label="Link to my Mastodon profile"><img class="h-8 w-8" src=/image/theme/mastodon-logo.svg alt="The Mastodon logo"></a></div></section><small class=pt-4>© skouf.com</small></footer></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-9NNFJW25R4"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-9NNFJW25R4")</script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.7.0/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script></body></html>